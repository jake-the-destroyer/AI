{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>CS4619: Artificial Intelligence 2</h1>\n",
    "<h2>Model Selection</h2>\n",
    "<h3>\n",
    "    Derek Bridge<br>\n",
    "    School of Computer Science and Information Technology<br>\n",
    "    University College Cork\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Initialization $\\newcommand{\\Set}[1]{\\{#1\\}}$ $\\newcommand{\\Tuple}[1]{\\langle#1\\rangle}$ $\\newcommand{\\v}[1]{\\pmb{#1}}$ $\\newcommand{\\cv}[1]{\\begin{bmatrix}#1\\end{bmatrix}}$ $\\newcommand{\\rv}[1]{[#1]}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Model Selection</h1>\n",
    "<p>\n",
    "    As discussed previously, the learning algorithm finds the values of parameters. But there are other parameters of\n",
    "    learning algorithms &mdash; ones that the learning algorithm does not set &mdash; which are called hyperparameters.\n",
    "    Our best example so far is the value of $k$ in kNN.\n",
    "</p>\n",
    "<p> \n",
    "    In this lecture, we look at ways of setting the values of the hyperparameters. This is called <b>model\n",
    "    selection</b>. Despite what it may sound like, this is not about choosing between different\n",
    "    learning algorithms (e.g. between OLS linear regression and kNN) &mdash; that, after all, can be done by\n",
    "    error estimation (which we discussed in a previous lecture). Model selection is about optimizing\n",
    "    the settings for each learning algorithm.\n",
    "</p>\n",
    "<p>\n",
    "    For some learning algorithms there might be special methods for setting some of the hyperparameters.\n",
    "    If not, in essence, you just try lots of values for your hyperparameters and see which is best &mdash; \n",
    "    an approach known as 'grid search'. But how do we estimate the error of each hyperparameter value that we try? \n",
    "    This is what we will discuss first.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Validation Sets</h2>\n",
    "<p>\n",
    "   As in the holdout method, we randomly partition the dataset into disjoint sets. Here, these partitions are\n",
    "   called the training set and the <b>validation set</b>. \n",
    "</p>\n",
    "<p>\n",
    "    For each value of the hyperparameter that you wish to try, you train the learning algorithm on the training set. \n",
    "    So, assuming one hyperparameter with $\\mathit{numvals}$ values that you wish to try, you will learn $\\mathit{numvals}$ models. Let's designate\n",
    "    them by $h_1,\\ldots,h_{\\mathit{numvals}}$. You test each of them on\n",
    "    the validation set, e.g. measuring mean squared error, as before. From this, you can see which of the\n",
    "    $numvals$ models (corresponding to $numvals$ different values of the hyperparameter) appears to be the best &mdash; the\n",
    "    one with the lowest error on the validation set. This gives you the value of the hyperparameter. That's\n",
    "    model selection.\n",
    "</p>\n",
    "<p>\n",
    "    The weakness of this (as before) is that the training and validation sets may not be representative: we may get\n",
    "    'lucky' or 'unlucky'. So we need to use <em>resampling</em> again: either repeated holdout, $k$-fold cross-validation,\n",
    "    repeated $k$-fold cross-validation, leave-one-out cross-validation, or one of the other methods that we did not study. For\n",
    "    concreteness, let's focus on one of them: $k$-fold cross-validation.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>$k$-Fold Cross-Validation for Model Selection</h2>\n",
    "<p>\n",
    "    To use $k$-fold cross-validation for model selection, you divide into $k$ folds. You take all but fold 1 as the\n",
    "    training set and you learn $\\mathit{numvals}$ models (one per hyperparameter value), and you test them on fold 1, recording the\n",
    "    mean squared error of each model. You repeat, taking a different fold to be the test set each time. For each\n",
    "    hyperparameter value, you take the mean of its $k$ mse's. The hyperparameter value with lowest mean mse is the value\n",
    "    that you should 'go live' with. (At this point, you can train on <em>all</em> the data, using the best\n",
    "    hyperparameter value that you have just discovered.) Here it is in pseudocode:\n",
    "</p>\n",
    "<ul style=\"background: lightgray; list-style: none\">\n",
    "    <li>\n",
    "        partition the dataset $D$ into $k$ disjoint equal-sized subsets, $T_1, T_2,\\ldots,T_k$\n",
    "    <li>\n",
    "    <li>\n",
    "        <b>for</b> $u = 1$ to $k$\n",
    "        <ul>\n",
    "            <li>\n",
    "                <b>for</b> $v = 1$ to $\\mathit{numvals}$\n",
    "                <ul>\n",
    "                    <li>train on $D \\setminus T_u$ with the $v$th hyperparameter value</li>\n",
    "                    <li>make predictions for $T_u$</li>\n",
    "                    <li>measure error (e.g. MSE)</li>\n",
    "                </ul>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "        get the mean of the errors for each hyperparameter value\n",
    "    </li>\n",
    "    <li>\n",
    "        report the hyperparameter value with lowest mean mse\n",
    "    </li>\n",
    "</ul>\n",
    "<p>\n",
    "    Let's now combine this validation set idea with grid search &mdash; and let's do so\n",
    "    in scikit-learn.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Grid Search</h2>\n",
    "<p>\n",
    "    <b>Grid search</b> is an 'exhaustive' approach &mdash; it tries every value for the hyperparameter (or, at least, all\n",
    "    values in a certain range). If there is more than one hyperparameter, it tries every combination of their values.\n",
    "</p>\n",
    "<ul>\n",
    "    <li>\n",
    "        If one hyperprameter has $\\mathit{numvals}_1$ values and another has $\\mathit{numvals}_2$ values, how many models will grid search train?\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Grid Search and Holdout in scikit-learn</h2>\n",
    "<p>\n",
    "    Let's try all values of kNN's hyperparameter $k$ between 1 and 10 for unweighted kNN on the Cork property dataset using\n",
    "    holdout (where we simply split the dataset once into training set and validation set):\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'std_score_time': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]), 'rank_test_score': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=int32), 'mean_train_score': array([  -189.60897436, -28748.9375    , -45408.66381766, -46205.99198718,\n",
      "       -48393.7374359 , -49434.63817664, -51196.90384615, -52501.96254006,\n",
      "       -54978.92679645, -56947.94211538]), 'mean_fit_time': array([ 0.00022936,  0.00027466,  0.00019097,  0.00019121,  0.00019288,\n",
      "        0.0001986 ,  0.00021362,  0.00020933,  0.00026512,  0.00019193]), 'split0_test_score': array([ -13169.20588235,  -38995.32352941,  -59840.95915033,\n",
      "        -78163.41636029,  -86328.64058824,  -93600.46732026,\n",
      "       -100748.29231693, -108507.90579044, -116618.70787945,\n",
      "       -122674.71044118]), 'mean_score_time': array([ 0.00041914,  0.00057435,  0.00038886,  0.00041723,  0.00040364,\n",
      "        0.00041223,  0.00041723,  0.00046158,  0.00050592,  0.00042892]), 'param_n_neighbors': masked_array(data = [1 2 3 4 5 6 7 8 9 10],\n",
      "             mask = [False False False False False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'std_test_score': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]), 'mean_test_score': array([ -13169.20588235,  -38995.32352941,  -59840.95915033,\n",
      "        -78163.41636029,  -86328.64058824,  -93600.46732026,\n",
      "       -100748.29231693, -108507.90579044, -116618.70787945,\n",
      "       -122674.71044118]), 'params': ({'n_neighbors': 1}, {'n_neighbors': 2}, {'n_neighbors': 3}, {'n_neighbors': 4}, {'n_neighbors': 5}, {'n_neighbors': 6}, {'n_neighbors': 7}, {'n_neighbors': 8}, {'n_neighbors': 9}, {'n_neighbors': 10}), 'std_train_score': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]), 'split0_train_score': array([  -189.60897436, -28748.9375    , -45408.66381766, -46205.99198718,\n",
      "       -48393.7374359 , -49434.63817664, -51196.90384615, -52501.96254006,\n",
      "       -54978.92679645, -56947.94211538]), 'std_fit_time': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])}\n",
      "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "          metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "          weights='uniform')\n",
      "-13169.2058824\n",
      "{'n_neighbors': 1}\n"
     ]
    }
   ],
   "source": [
    "# Use pandas to read the CSV file\n",
    "df = pd.read_csv(\"dataset-corkA.csv\")\n",
    "\n",
    "# Get the feature-values and the target values into separate numpy arrays of numbers\n",
    "X = df[['flarea', 'bdrms', 'bthrms']].values\n",
    "y = df['price'].values\n",
    "\n",
    "# Create kNN Regressor object\n",
    "estimator = KNeighborsRegressor()\n",
    "\n",
    "# Dictionary containing each hyperparameter and the hyperparameter#s possible values \n",
    "hyperparameters = {'n_neighbors' : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "\n",
    "# We want to split the dataset just once into training and validation\n",
    "ss = ShuffleSplit(n_splits = 1, test_size = 0.3)\n",
    "\n",
    "# And here we create the Grid Search object and run its fit method\n",
    "gs = GridSearchCV(estimator, hyperparameters, scoring = 'neg_mean_squared_error', cv = ss)\n",
    "gs.fit(X, y)\n",
    "\n",
    "# Display some of its instance variables afterwards\n",
    "print(gs.cv_results_)\n",
    "print(gs.best_estimator_)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    This suggests a particular value for $k$. But, remember, we are doing only one split of the data. Re-run it and you \n",
    "    will see that the best value for the hyperparameter differs from run to run.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Grid Search and $k$-Fold Cross-Validation in scikit-learn</h2>\n",
    "<p>\n",
    "    If we want to do $k$-fold cross-validation instead (which we hope will give a more robust answer), we simply feed a\n",
    "    different cross-validation method into the grid search. As we saw before, scikit-learn\n",
    "    makes it very easy to choose $k$-fold cross-validation: simply supply the number\n",
    "    of folds (but, remember, you may need to do your own shuffling):\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'split2_train_score': array([  -484.09950249, -25589.34452736, -53233.55776672, -51515.16075871,\n",
      "       -56559.79621891, -58103.73231067, -61479.01319931, -64792.29337687,\n",
      "       -69132.5631718 , -72318.99691542]), 'split8_test_score': array([-6497.81818182, -4773.09090909, -4879.05050505, -5707.80965909,\n",
      "       -5204.12727273, -5143.66792929, -4922.05380334, -5193.40767045,\n",
      "       -4869.08361392, -4660.97772727]), 'split4_train_score': array([  -452.12871287, -13167.84282178, -41085.96644664, -56588.97741337,\n",
      "       -57259.14950495, -61631.63723872, -62278.2208527 , -64311.56079827,\n",
      "       -66987.55610561, -70195.60311881]), 'std_score_time': array([  9.78169136e-05,   4.80696793e-05,   6.53671397e-06,\n",
      "         5.60988328e-06,   9.21924908e-06,   2.36139009e-05,\n",
      "         3.94680412e-04,   9.46444915e-05,   3.30601212e-05,\n",
      "         4.02091714e-05]), 'split0_test_score': array([-358085.56521739, -482873.84782609, -370830.08695652,\n",
      "       -221937.86141304, -144408.27304348,  -98501.71618357,\n",
      "        -66916.32830524,  -45250.75543478,  -31963.05099302,\n",
      "        -26488.22826087]), 'split5_test_score': array([-735935.04545455, -731675.25      , -783189.53535354,\n",
      "       -773282.86647727, -798370.98181818, -829879.65782828,\n",
      "       -869560.18089054, -870708.27698864, -873867.09820426,\n",
      "       -888116.86545455]), 'std_test_score': array([ 227966.03512856,  241539.93825974,  240470.39761414,\n",
      "        226696.90481838,  231158.59013601,  240918.18811507,\n",
      "        253615.51771752,  254913.02815885,  256538.17240714,\n",
      "        261108.12406223]), 'param_n_neighbors': masked_array(data = [1 2 3 4 5 6 7 8 9 10],\n",
      "             mask = [False False False False False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'params': ({'n_neighbors': 1}, {'n_neighbors': 2}, {'n_neighbors': 3}, {'n_neighbors': 4}, {'n_neighbors': 5}, {'n_neighbors': 6}, {'n_neighbors': 7}, {'n_neighbors': 8}, {'n_neighbors': 9}, {'n_neighbors': 10}), 'split6_train_score': array([  -448.04455446, -13354.29579208, -40811.53575358, -56462.90717822,\n",
      "       -57375.70435644, -61431.18633113, -62579.13093554, -64697.01593441,\n",
      "       -66925.09650409, -70411.22683168]), 'split1_test_score': array([-25737.43478261, -28772.47826087, -23333.54589372, -17079.82880435,\n",
      "       -15249.00521739, -14477.90821256, -13502.53327418, -13005.79076087,\n",
      "       -13552.9538379 , -14947.20217391]), 'split0_train_score': array([  -537.70646766, -13148.31343284, -30777.01381979, -36621.03731343,\n",
      "       -46704.19701493, -51461.54339414, -56657.91288456, -62447.6059546 ,\n",
      "       -67453.81020822, -70193.51487562]), 'std_fit_time': array([  6.85205041e-05,   8.41249407e-07,   1.11918669e-05,\n",
      "         4.87541219e-06,   7.74387068e-06,   8.58906033e-06,\n",
      "         6.72615997e-05,   2.11655548e-05,   1.73185129e-05,\n",
      "         9.31252715e-06]), 'split2_test_score': array([  -9029.65217391,  -72458.09782609, -140598.24154589,\n",
      "        -79681.95380435,  -51231.68347826,  -34125.44444444,\n",
      "        -23277.85803017,  -15041.41711957,   -9248.49006978,\n",
      "         -6249.00173913]), 'rank_test_score': array([ 8, 10,  9,  7,  6,  5,  4,  3,  1,  2], dtype=int32), 'mean_train_score': array([  -482.0276809 , -13517.95782289, -37491.45069455, -48967.95883085,\n",
      "       -50827.81511847, -54108.21725613, -55898.84664353, -58615.37603385,\n",
      "       -61435.64677958, -64195.52369982]), 'mean_fit_time': array([ 0.00031419,  0.00019491,  0.0001996 ,  0.00019498,  0.00019808,\n",
      "        0.0001971 ,  0.00026267,  0.00024872,  0.00021396,  0.00019896]), 'std_train_score': array([    56.83159464,   4927.75255594,  11851.05312687,  15692.04160199,\n",
      "        15444.7979396 ,  16339.79574485,  16426.1052164 ,  17258.13578814,\n",
      "        18064.07601894,  18941.0691304 ]), 'split9_test_score': array([-20006.        , -10565.43181818, -10863.3989899 , -29318.28693182,\n",
      "       -64317.38545455, -46908.48358586, -37436.66512059, -28398.9609375 ,\n",
      "       -23767.06116723, -19971.00045455]), 'mean_test_score': array([-120836.04910714, -137319.21428571, -136624.22569444,\n",
      "       -114827.41462054, -109692.46892857, -104796.04501488,\n",
      "       -103158.51576166,  -99171.72112165,  -96955.54249339,\n",
      "        -97213.61928571]), 'split3_test_score': array([-8213.08695652, -8079.86956522, -5914.74879227, -5775.69836957,\n",
      "       -5400.9826087 , -5700.20531401, -5326.28305235, -4992.24320652,\n",
      "       -4351.19108964, -4110.90434783]), 'split7_test_score': array([-16809.36363636, -11734.71590909, -12835.93434343, -10750.91477273,\n",
      "       -10627.12      , -12933.62121212, -11902.52411874, -12124.86363636,\n",
      "       -11206.04377104, -11253.18909091]), 'split8_train_score': array([  -434.05940594, -13399.17326733, -41283.02365237, -56969.50433168,\n",
      "       -57282.33089109, -61205.6029978 , -62459.21832693, -64463.36370668,\n",
      "       -67250.70223689, -70106.52836634]), 'mean_score_time': array([ 0.00052178,  0.00037928,  0.00035717,  0.00035968,  0.00036392,\n",
      "        0.00037596,  0.00057778,  0.0004781 ,  0.00040765,  0.00038707]), 'split4_test_score': array([-9990.95454545, -9186.94318182, -7514.02020202, -6713.96875   ,\n",
      "       -7416.47636364, -7242.91414141, -7946.19387755, -6143.27201705,\n",
      "       -6774.08024691, -6619.50727273]), 'split7_train_score': array([  -486.53465347, -13390.88861386, -40769.35753575, -56456.43409653,\n",
      "       -57280.19227723, -61343.19361936, -61706.21206304, -63816.35960705,\n",
      "       -66468.29727417, -69565.44594059]), 'split1_train_score': array([  -509.85074627, -12565.68532338, -40071.00221117, -56085.81343284,\n",
      "       -56763.54129353, -60877.8685738 , -61783.664636  , -64159.89894279,\n",
      "       -67377.84251582, -70521.31960199]), 'split9_train_score': array([  -610.8960396 , -13463.53960396, -40436.48734873, -56532.76670792,\n",
      "       -56260.51247525, -57355.45214521, -60518.17215599, -65849.8856745 ,\n",
      "       -68060.16196064, -70744.30019802]), 'split6_test_score': array([-21795.5       , -11122.07954545,  -6548.25252525,  -4153.78977273,\n",
      "        -4811.37818182,  -5154.96338384,  -4595.03988868,  -5330.79971591,\n",
      "        -4897.57575758,  -5040.18636364]), 'split3_train_score': array([  -399.25870647, -13373.45895522, -41112.16252073, -57025.51430348,\n",
      "       -57359.00477612, -61725.71310116, -62647.05777236, -64716.94636194,\n",
      "       -67417.957865  , -70489.61223881]), 'split5_train_score': array([ -457.6980198 , -3727.03589109, -5334.39988999, -5421.47277228,\n",
      "       -5433.72237624, -5946.24284928, -6879.86360881, -6898.82998144,\n",
      "       -7282.47995355, -7408.68891089])}\n",
      "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "          metric_params=None, n_jobs=1, n_neighbors=9, p=2,\n",
      "          weights='uniform')\n",
      "-96955.5424934\n",
      "{'n_neighbors': 9}\n"
     ]
    }
   ],
   "source": [
    "# Create the Grid Search object and run its fit method\n",
    "gs = GridSearchCV(estimator, hyperparameters, scoring = 'neg_mean_squared_error', cv = 10)\n",
    "gs.fit(X, y)\n",
    "\n",
    "# Display some of its instance variables afterwards\n",
    "print(gs.cv_results_)\n",
    "print(gs.best_estimator_)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    It selects $k = 9$ (although if we were shuffling the dataset, we might still get different answers each time we run it, but with a lot less\n",
    "    variability than before).\n",
    "</p>\n",
    "<p>\n",
    "    Assuming we now want to 'go live', we would train 9NN on <em>all</em> the data.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Error Estimation, again</h1>\n",
    "<p>\n",
    "    Suppose you want to do error estimation, as before, i.e. you want to know how well a model\n",
    "    is likely to perform on unseen data. But suppose there is a hyperparameter and so you want \n",
    "    your estimate of the error on unseen data to use a good value for the hyperparameter. In this case, we need to combine\n",
    "    ideas from the earlier part of this lecture with ideas from the error estimation lecture.\n",
    "</p>\n",
    "<p>\n",
    "    The simplest case is to partition your data into three sets (assuming you have enough data!):\n",
    "</p>\n",
    "<ul>\n",
    "    <li>\n",
    "        training set,\n",
    "    </li>\n",
    "    <li>\n",
    "        validation set, and\n",
    "    </li>\n",
    "    <li>\n",
    "        test set.\n",
    "    </li>\n",
    "</ul>\n",
    "<p>\n",
    "    You use the training set and the validation set to choose the best value for the hyperparameter, i.e. train $\\mathit{numvals}$\n",
    "    models (one for each value of the hyperparameter), test them on the validation set, using grid search.\n",
    "    Choose the value that gave\n",
    "    the lowest mse. Then, test the model you have just selected on the test set: the mse that this produces is your\n",
    "    estimate of the error on unseen examples.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Training Set, Validation Set and Test Set in scikit-learn</h2>\n",
    "<p>\n",
    "    In this scikit-learn example, we will split the data 60-20-20:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181434.79288888889"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data 80/20: the 80 is the combined training and validation sets; the 20 is the final test set\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "# Split the combined set just once into training and validation: 75/25 gives 60/20 of the original data\n",
    "ss = ShuffleSplit(n_splits = 1, test_size = 0.25, random_state = np.random)\n",
    "\n",
    "# And here we create the Grid Search object and run its fit method\n",
    "gs = GridSearchCV(estimator, hyperparameters, scoring = 'neg_mean_squared_error', cv = ss)\n",
    "gs.fit(X_train_val, y_train_val)\n",
    "\n",
    "# Take the best estimator found by the grid search\n",
    "# Test it on the test set \n",
    "y_predicted = gs.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test, y_predicted)\n",
    "\n",
    "# Display\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    This estimate has the weakness (again) that it is based on just one way of partitioning the data: different partitions\n",
    "    will have very different error estimates &mdash; as you can confirm by running the code seveal times.\n",
    "    We need to use resampling.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Nested $k$-Fold Cross-Validation</h2>\n",
    "<p>\n",
    "    What we will do is called <b>nested $k$-fold cross validation</b>. As usual, it partitions the dataset into $k$ folds.\n",
    "    One fold is kept as the test set. The remaining data is then partitioned again into $k$ folds. One of <em>these</em>\n",
    "    folds is kept as the validation set. The remaining is used for training. We learn $\\mathit{numvals}$ models from the training data\n",
    "    (one for each value of the hyperparameter). We test each of them on the validation set. We repeat this, taking each\n",
    "    <em>inner fold</em> in turn as the validation set. When we have done, we can select the best value of the hyperparameter.\n",
    "    We test this model on the <em>outer fold</em> that we kept as test set. Then the whole thing repeats: a different outer\n",
    "    fold becomes the test set; $k$-fold cross-validation is run on the remaining data to find another best value for\n",
    "    the hyperparameter; and this model is tested on the outer fold that was kept as test set. And so on.\n",
    "</p>\n",
    "<p>\n",
    "    In pseudocode:\n",
    "</p>\n",
    "<ul style=\"background: lightgray; list-style: none\">\n",
    "    <li>\n",
    "        partition the dataset $D$ into $k$ disjoint equal-sized subsets, $T_1, T_2,\\ldots,T_k$\n",
    "    <li>\n",
    "    <li>\n",
    "        <b>for</b> $u_1 = 1$ to $k$\n",
    "        <ul>\n",
    "            <li>\n",
    "                let $D'$ be $D \\setminus T_{u_1}$\n",
    "            </li>\n",
    "            <li>\n",
    "                partition $D'$ into $k$ disjoint equal-sized subsets, $S_1, S_2,\\ldots,S_k$\n",
    "            </li>\n",
    "            <li>\n",
    "                <b>for</b> $u_2 = 1$ to $k$\n",
    "                <ul>\n",
    "                    <li>\n",
    "                        <b>for</b> $v = 1$ to $\\mathit{numvals}$\n",
    "                        <ul>\n",
    "                            <li>train on $D' \\setminus S_{u_2}$ with the $v$th hyperparameter value</li>\n",
    "                            <li>make predictions for $S_{u_2}$</li>\n",
    "                            <li>measure validation error (e.g. MSE)</li>\n",
    "                        </ul>\n",
    "                    </li>\n",
    "                </ul>\n",
    "            </li>\n",
    "            <li>\n",
    "                get the mean of the errors for each hyperparameter value\n",
    "            </li>\n",
    "            <li>\n",
    "                select the model (hyperparameter value) with lowest mean mse\n",
    "            </li>\n",
    "            <li>\n",
    "                use the selected model to make predictions for $T_{u_1}$\n",
    "            </li>\n",
    "            <li>\n",
    "                measure test error (e.g. MSE)\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "        report the means of the test errors\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Nested $k$-Fold Cross-Validation in scikit-learn</h2>\n",
    "<p>\n",
    "    This is the short version again (but again you should probably shuffle the dataset first):\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-101001.56507719708"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(estimator, hyperparameters, scoring = 'neg_mean_squared_error', cv = 10)\n",
    "mses_test = cross_val_score(gs, X, y, scoring = 'neg_mean_squared_error', cv = 10)\n",
    "mean_mse_test = np.mean(mses_test)\n",
    "mean_mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    Of course, our little dataset really isn't big enough for this kind of treatment.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Confusion</h2>\n",
    "<p>\n",
    "    You might be thinking to yourself: \"But the best value for the hyperparameter can be different for each outer fold.\" You are\n",
    "    correct. And so then you may be thinking: \"So which value for the hyperparameter do I choose?\" To which the reply is: \n",
    "    \"None of them. This is not model selection. This is just error estimation.\" If you want to do model selection, see\n",
    "    earlier.\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
